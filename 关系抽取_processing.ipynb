{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AshjnycjsHIp",
        "outputId": "056aa054-9d4e-49ec-cb01-0d506dbbbfef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['sent_relation_dev.txt',\n",
              " 'sent_dev.txt',\n",
              " 'sent_test.txt',\n",
              " 'sent_relation_test.txt',\n",
              " 'bag_relation_train.txt',\n",
              " 'sent_relation_train.txt',\n",
              " 'bag_relation_test.txt',\n",
              " 'relation2id.txt',\n",
              " 'text.txt',\n",
              " 'sent_train.txt',\n",
              " 'bag_relation_dev.txt',\n",
              " 'readme',\n",
              " 'hit_stopwords.txt',\n",
              " 'w2v',\n",
              " 'text1.txt']"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive/关系抽取/\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fft4-AyRFAez"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6Yh54IBvcyV"
      },
      "outputs": [],
      "source": [
        "import jieba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9_iVwymv2Ye"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8czvhw6-spuj"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    data = pd.read_csv(path,delimiter='\\t',header=None)\n",
        "    data.columns = ['sent_id','e1','e2','text']\n",
        "    for col in ['e1','e2','text']:\n",
        "        data[col] = data[col].map(lambda x:str(x).lower())\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccy40IFUEi78"
      },
      "outputs": [],
      "source": [
        "sent_train=load_data('sent_train.txt')\n",
        "sent_test=load_data('sent_test.txt')\n",
        "sent_dev=load_data('sent_dev.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDhfKSkeFFqT"
      },
      "outputs": [],
      "source": [
        "def load_relation(path, bag=False):\n",
        "    label = pd.read_csv(path,delimiter='\\t',header=None)\n",
        "    if bag:\n",
        "        label.columns = ['bag_id','e1','e2','sent_ids','label']\n",
        "    else:\n",
        "        label.columns = ['sent_id','label']\n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbw3LzdPFPc8"
      },
      "outputs": [],
      "source": [
        "train_label=load_relation('sent_relation_train.txt', bag=False)\n",
        "#sent_relation_test=load_relation('sent_relation_test.txt', bag=False)\n",
        "dev_label=load_relation('sent_relation_dev.txt', bag=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pGduTV4JIk2"
      },
      "outputs": [],
      "source": [
        "sent_train = sent_train.merge(train_label, on='sent_id', how='left')\n",
        "sent_dev = sent_dev.merge(dev_label, on='sent_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E23FUOrDJaWm"
      },
      "outputs": [],
      "source": [
        "sent_train['label'] = sent_train['label'].map(lambda x: int(str(x).split(' ')[0]))\n",
        "sent_dev['label'] = sent_dev['label'].map(lambda x: int(str(x).split(' ')[0]))\n",
        "# 根据空格分词\n",
        "sent_train['text_seg'] = sent_train['text'].map(lambda x: str(x).lower().split(' '))\n",
        "sent_dev['text_seg'] = sent_dev['text'].map(lambda x: str(x).lower().split(' '))\n",
        "sent_test['text_seg'] = sent_test['text'].map(lambda x: str(x).split(' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2vUaRnNKIml",
        "outputId": "85f7cca1-2a80-497d-ecb5-8cc82e1a5952"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         [韩国, 梦想, 演唱会, 第十届, 2004, 年, :, mc, :, 金泰熙, ，, ...\n",
              "1         [林散之, 先生, 等, 当代, 名家, 对, 辛文山, 先生, 的, 书法, 均, 有, ...\n",
              "2         [吉莱斯, ·, 勒华, 人物, 生平, :, 吉莱斯, ·, 勒华, 1958, 年, 1...\n",
              "3         [（, 原, 重庆, 警备区, 顾问, ）, :, 张铭, （, 1920, —, ), ，...\n",
              "4         [中国, 工艺美术, 大师, 张育贤, 先生, ，, 景德镇市, 美术家, 协会主席, 、,...\n",
              "                                ...                        \n",
              "281236    [李彪, 敏感, 地, 看出, 了, 周武, 、, 李英姿, 、, 周双, 和, 刘大壮, ...\n",
              "281237    [高则, 让, 夏侯杰, 信, 他, 赵子龙, 确是, 细作, ，, 但, 夏侯杰, 称失,...\n",
              "281238    [回到, 真, 定县, 的, 子龙到, 李全, 的, 坟, 前, 进行, 祭拜, ，, 却,...\n",
              "281239    [可是, ，, 他, 却, 没有, 想到, ，, 暗中, 观察, 的, 高则, ，, 竟然,...\n",
              "281240    [他, 坦然, 承认, 夏侯杰, 正是, 死, 在, 自己, 手里, 的, ，, 并, 问轻...\n",
              "Name: text_seg, Length: 281241, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_train.text_seg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPK1Kbf2J7lM"
      },
      "source": [
        "## Build vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5kzbnFJKBL6",
        "outputId": "cd8c652c-bfaa-4f3f-e9c4-692609b98f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "stop words size 767\n"
          ]
        }
      ],
      "source": [
        "def load_stop_words(stop_word_path):\n",
        "    '''\n",
        "    加载停用词\n",
        "    :param stop_word_path:停用词路径\n",
        "    :return: 停用词表 list\n",
        "    '''\n",
        "    file = open(stop_word_path, 'r', encoding='utf-8')\n",
        "    stop_words = file.readlines()\n",
        "    stop_words = [stop_word.strip() for stop_word in stop_words]\n",
        "    return stop_words\n",
        "\n",
        "stop_words=load_stop_words('hit_stopwords.txt')\n",
        "print('stop words size {}'.format(len(stop_words)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHXQXCc3MpIo"
      },
      "outputs": [],
      "source": [
        "def filter_stopwords(words):\n",
        "    '''\n",
        "    过滤停用词\n",
        "    :param seg_list: 切好词的列表 [word1 ,word2 .......]\n",
        "    :return: 过滤后的停用词\n",
        "    '''\n",
        "    return [word for word in words if word not in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXVghosZMtGI"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(sent):\n",
        "  for i in range(len(sent.text_seg)):\n",
        "    sent.text_seg[i]=filter_stopwords(sent.text_seg[i])\n",
        "  return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v7CjNzKJ6BY"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "all_text_list = []\n",
        "for v in sent_train['text_seg'].values:\n",
        "    all_text_list += v\n",
        "text_dict = Counter(all_text_list)\n",
        "new_text_dict = {key: text_dict[key] for key in text_dict.keys() if text_dict[key] >= 5}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26EgztRCPMao"
      },
      "outputs": [],
      "source": [
        "def get_entity_idx(data):\n",
        "    data['e1_idx'] = data[['e1','text_seg']].apply(lambda x:x['text_seg'].index(x['e1']),axis=1)\n",
        "    data['e2_idx'] = data[['e2' ,'text_seg']].apply(lambda x:x['text_seg'].index(x['e2']),axis=1)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Q8_ehpjPZzj"
      },
      "outputs": [],
      "source": [
        "# 获取实体在序列中的位置，目前只标记位于第一个的位置，多次出现的暂无处理方法\n",
        "sent_train = get_entity_idx(sent_train)\n",
        "sent_dev = get_entity_idx(sent_dev)\n",
        "sent_test = get_entity_idx(sent_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGZXyEhQPNj-"
      },
      "outputs": [],
      "source": [
        "# 获取句子中其他词与实体之间的距离，实际中可能用位置向量较多，但实际意义相同\n",
        "def get_pos_distance(data):\n",
        "    data['e1_distance'] = data[['e1_idx','text_seg']].apply(lambda x:[i-x['e1_idx'] for i in range(len(x['text_seg']))],axis=1)\n",
        "    data['e2_distance'] = data[['e2_idx','text_seg']].apply(lambda x:[i-x['e2_idx'] for i in range(len(x['text_seg']))],axis=1)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ettA4N8xPhnw"
      },
      "outputs": [],
      "source": [
        "# 获取句子中其他词与实体之间的距离，实际中可能用位置向量较多，但实际意义相同\n",
        "sent_train = get_pos_distance(sent_train)\n",
        "sent_dev = get_pos_distance(sent_dev)\n",
        "sent_test = get_pos_distance(sent_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfNPPi9UwqHC",
        "outputId": "e70d2d72-6a13-40be-f160-b1dadbaa7153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bag_relation_dev.txt\trelation2id.txt\t\t sent_test.txt\n",
            "bag_relation_test.txt\tsent_dev.txt\t\t sent_train.txt\n",
            "bag_relation_train.txt\tsent_relation_dev.txt\t text1.txt\n",
            "hit_stopwords.txt\tsent_relation_test.txt\t text.txt\n",
            "readme\t\t\tsent_relation_train.txt  w2v\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er0qNOD1vDaR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def get_w2v():\n",
        "    #os.mkdir('./w2v/')\n",
        "    sent_train = pd.read_csv('sent_train.txt', delimiter='\\t', header=None)\n",
        "    sent_dev = pd.read_csv('sent_dev.txt', delimiter='\\t', header=None)\n",
        "    sent_test = pd.read_csv('sent_test.txt', delimiter='\\t', header=None)\n",
        "    '''加载与训练预测相关的数据'''\n",
        "    sent_train.columns = ['sent_id', 'e1', 'e2', 'text']\n",
        "    sent_dev.columns = ['sent_id', 'e1', 'e2', 'text']\n",
        "    sent_test.columns = ['sent_id', 'e1', 'e2', 'text']\n",
        "    '''加载语料，用来训练词向量'''\n",
        "    text = []\n",
        "    with open('text.txt', 'r', encoding='utf8') as f:\n",
        "        for line in f.readlines():\n",
        "            text.append(line.strip('\\n'))\n",
        "    text=text[:1000000]\n",
        "    all_text = pd.concat([sent_train['text'], sent_dev['text'], sent_test['text']])\n",
        "    all_text = [str(v).lower() for v in all_text]\n",
        "    text_seg = [v.split(' ') for v in all_text]\n",
        "    all_word = []\n",
        "    for v in text_seg:\n",
        "        all_word += v\n",
        "    word_cnt = Counter(all_word)\n",
        "    for word in word_cnt.keys():\n",
        "        jieba.add_word(word)\n",
        "    text_seg_corpus = [jieba.lcut(v) for v in text]\n",
        "    text_seg_all = text_seg + text_seg_corpus\n",
        "    w2v = Word2Vec(size=128)\n",
        "    w2v.build_vocab(text_seg_all)\n",
        "    w2v.train(text_seg_all, total_examples=w2v.corpus_count, epochs=5)\n",
        "    w2v.save('./w2v/w2v_model.w2v')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7kv65uPwZj9",
        "outputId": "44a9dd18-fee8-4102-c199-b3cff4f84105"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.896 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ]
        }
      ],
      "source": [
        "get_w2v()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P6hPyXB3BT6j"
      },
      "outputs": [],
      "source": [
        "def get_word_index(text, index_word):\n",
        "    idx_res = []\n",
        "    for x in text:\n",
        "        tmp = []\n",
        "        for v in x:\n",
        "            try:\n",
        "                tmp.append(index_word[v])\n",
        "            except KeyError:\n",
        "                tmp.append(1)\n",
        "        idx_res.append(tmp)\n",
        "    return idx_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0k0872OdWoXR"
      },
      "outputs": [],
      "source": [
        "w2v_model = Word2Vec.load('./w2v/w2v_model.w2v')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4fFPib3Plfr",
        "outputId": "6c3f25aa-27fc-4912-eff1-cc90321bb0f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        }
      ],
      "source": [
        "# 判断哪些词在词向量模型中，因为要确定UNK 和 PAD\n",
        "word_in_w2v = []\n",
        "for key in new_text_dict.keys():\n",
        "    if key in w2v_model:\n",
        "        word_in_w2v.append(key)\n",
        "    # 建立索引到词的映射\n",
        "word_index = dict()\n",
        "word_index[0] = 'PAD'\n",
        "word_index[1] = 'UNK'\n",
        "for i, word in enumerate(word_in_w2v):\n",
        "    word_index[i + 2] = word\n",
        "index_word = {word_index[key]: key for key in word_index.keys()}\n",
        "    # 建立词向量矩阵\n",
        "word_matrix = np.zeros((len(word_index), 128))\n",
        "for key in word_index:\n",
        "    if word_index[key] not in ['UNK', 'PAD']:\n",
        "        word_matrix[key] = w2v_model[word_index[key]]\n",
        "    # 将字转换成索引\n",
        "sent_train['word_index'] = get_word_index(sent_train['text_seg'], index_word)\n",
        "sent_dev['word_index'] = get_word_index(sent_dev['text_seg'], index_word)\n",
        "sent_test['word_index'] = get_word_index(sent_test['text_seg'], index_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1r-nTJ5TYEQh"
      },
      "outputs": [],
      "source": [
        "def change_entity_idx(x):\n",
        "    for i,v in enumerate(x['text_seg']):\n",
        "        if v == x['e1']:\n",
        "            x['word_index'][i] = 1\n",
        "        if v == x['e2']:\n",
        "            x['word_index'][i] = 1\n",
        "    return x['word_index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rSAghHHzZKoU"
      },
      "outputs": [],
      "source": [
        "def modify_pos_idx(x):\n",
        "    tmp = []\n",
        "    for v in x:\n",
        "        if v < 0:\n",
        "            tmp.append(1)\n",
        "        elif v > 99:\n",
        "            tmp.append(99)\n",
        "        else:\n",
        "            tmp.append(v)\n",
        "    return tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zKd8vIn8W7PY"
      },
      "outputs": [],
      "source": [
        "# 将字转换成索引\n",
        "sent_train['word_index'] = get_word_index(sent_train['text_seg'], index_word)\n",
        "sent_dev['word_index'] = get_word_index(sent_dev['text_seg'], index_word)\n",
        "sent_test['word_index'] = get_word_index(sent_test['text_seg'], index_word)\n",
        "# 为了避免模型学到错误的信息，将所有的实体都替换成1\n",
        "sent_train['word_index'] = sent_train[['e1','e2','text_seg','word_index']].apply(change_entity_idx, axis=1)\n",
        "sent_dev['word_index'] = sent_dev[['e1','e2','text_seg','word_index']].apply(change_entity_idx, axis=1)\n",
        "sent_test['word_index'] = sent_test[['e1','e2','text_seg','word_index']].apply(change_entity_idx, axis=1)\n",
        "# 将位置向量中大于预定长度的转换到合适的长度\n",
        "sent_train['e1_distance'] = sent_train['e1_distance'].map(modify_pos_idx)\n",
        "sent_train['e2_distance'] = sent_train['e2_distance'].map(modify_pos_idx)\n",
        "sent_dev['e1_distance'] = sent_dev['e1_distance'].map(modify_pos_idx)\n",
        "sent_dev['e2_distance'] = sent_dev['e2_distance'].map(modify_pos_idx)\n",
        "sent_test['e1_distance'] = sent_test['e1_distance'].map(modify_pos_idx)\n",
        "sent_test['e2_distance'] = sent_test['e2_distance'].map(modify_pos_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uhGbiNPobSy4"
      },
      "outputs": [],
      "source": [
        "\n",
        "#长度不足50 用0补全\n",
        "def get_sent_padding(data):\n",
        "    data['word_index'] = data['word_index'].map(lambda x:x[:50])\n",
        "    data['word_index'] = data['word_index'].map(lambda x:x + [0]*(50-len(x)))\n",
        "    data['e1_distance'] = data['e1_distance'].map(lambda x:x[:50])\n",
        "    data['e1_distance'] = data['e1_distance'].map(lambda x:x + [0]*(50-len(x)))\n",
        "    data['e2_distance'] = data['e2_distance'].map(lambda x:x[:50])\n",
        "    data['e2_distance'] = data['e2_distance'].map(lambda x:x + [0]*(50-len(x)))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "4Mv70TAXeRam",
        "outputId": "0f1e2d7c-2397-42d4-9416-1b88721953b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-43fb47c2-0613-4844-a591-7bd938d2c758\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_id</th>\n",
              "      <th>e1</th>\n",
              "      <th>e2</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_seg</th>\n",
              "      <th>e1_idx</th>\n",
              "      <th>e2_idx</th>\n",
              "      <th>e1_distance</th>\n",
              "      <th>e2_distance</th>\n",
              "      <th>word_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_SENT_ID_000001</td>\n",
              "      <td>金泰熙</td>\n",
              "      <td>金东</td>\n",
              "      <td>韩国 梦想 演唱会 第十届 2004 年 : mc : 金泰熙 ， 金东 万</td>\n",
              "      <td>0</td>\n",
              "      <td>[韩国, 梦想, 演唱会, 第十届, 2004, 年, :, mc, :, 金泰熙, ，, ...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 3]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]</td>\n",
              "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 8, 1, 11, 1, 12]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43fb47c2-0613-4844-a591-7bd938d2c758')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43fb47c2-0613-4844-a591-7bd938d2c758 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43fb47c2-0613-4844-a591-7bd938d2c758');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                sent_id   e1  e2                                    text  \\\n",
              "0  TRAIN_SENT_ID_000001  金泰熙  金东  韩国 梦想 演唱会 第十届 2004 年 : mc : 金泰熙 ， 金东 万   \n",
              "\n",
              "   label                                           text_seg  e1_idx  e2_idx  \\\n",
              "0      0  [韩国, 梦想, 演唱会, 第十届, 2004, 年, :, mc, :, 金泰熙, ，, ...       9      11   \n",
              "\n",
              "                               e1_distance  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 3]   \n",
              "\n",
              "                               e2_distance  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]   \n",
              "\n",
              "                                  word_index  \n",
              "0  [2, 3, 4, 5, 6, 7, 8, 9, 8, 1, 11, 1, 12]  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_train.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "CEveYaaeWIYW",
        "outputId": "564f2f4b-a658-47cf-b164-e9274b6df262"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b14b4f0c-e1fa-488c-b368-a204ffcd06c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_id</th>\n",
              "      <th>e1</th>\n",
              "      <th>e2</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_seg</th>\n",
              "      <th>e1_idx</th>\n",
              "      <th>e2_idx</th>\n",
              "      <th>e1_distance</th>\n",
              "      <th>e2_distance</th>\n",
              "      <th>word_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_SENT_ID_000001</td>\n",
              "      <td>金泰熙</td>\n",
              "      <td>金东</td>\n",
              "      <td>韩国 梦想 演唱会 第十届 2004 年 : mc : 金泰熙 ， 金东 万</td>\n",
              "      <td>0</td>\n",
              "      <td>[韩国, 梦想, 演唱会, 第十届, 2004, 年, :, mc, :, 金泰熙, ，, ...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 3]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]</td>\n",
              "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 8, 1, 11, 1, 12]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b14b4f0c-e1fa-488c-b368-a204ffcd06c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b14b4f0c-e1fa-488c-b368-a204ffcd06c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b14b4f0c-e1fa-488c-b368-a204ffcd06c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                sent_id   e1  e2                                    text  \\\n",
              "0  TRAIN_SENT_ID_000001  金泰熙  金东  韩国 梦想 演唱会 第十届 2004 年 : mc : 金泰熙 ， 金东 万   \n",
              "\n",
              "   label                                           text_seg  e1_idx  e2_idx  \\\n",
              "0      0  [韩国, 梦想, 演唱会, 第十届, 2004, 年, :, mc, :, 金泰熙, ，, ...       9      11   \n",
              "\n",
              "                               e1_distance  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 3]   \n",
              "\n",
              "                               e2_distance  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]   \n",
              "\n",
              "                                  word_index  \n",
              "0  [2, 3, 4, 5, 6, 7, 8, 9, 8, 1, 11, 1, 12]  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_train.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tqB1DNebbUAi"
      },
      "outputs": [],
      "source": [
        "# 对于相同实体对的句子，进行集包处理\n",
        "\n",
        "def get_group_data(data):\n",
        "    idx_grp = data.groupby(['e1','e2']).apply(lambda x:x['word_index'].values).reset_index()\n",
        "    idx_grp.columns = ['e1','e2','word_idx']\n",
        "    pos1_grp = data.groupby(['e1','e2']).apply(lambda x:x['e1_distance'].values).reset_index()\n",
        "    pos1_grp.columns = ['e1','e2','e1_distance']\n",
        "    pos2_grp = data.groupby(['e1','e2']).apply(lambda x:x['e2_distance'].values).reset_index()\n",
        "    pos2_grp.columns = ['e1','e2','e2_distance']\n",
        "    idx_grp  = idx_grp.merge(pos1_grp,on=['e1','e2'],how='left')\n",
        "    idx_grp  = idx_grp.merge(pos2_grp,on=['e1','e2'],how='left')\n",
        "    return idx_grp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3rtS0z5fbWJw"
      },
      "outputs": [],
      "source": [
        "def get_group_padding(data):\n",
        "    data['word_idx'] = data['word_idx'].map(lambda x:x.tolist()+ [[0]*50]*(50-len(x)))\n",
        "    data['e1_distance'] = data['e1_distance'].map(lambda x:x.tolist()+ [[0]*50]*(50-len(x)))\n",
        "    data['e2_distance'] = data['e2_distance'].map(lambda x:x.tolist()+ [[0]*50]*(50-len(x)))\n",
        "    data['word_idx'] = data['word_idx'].map(lambda x:x[:50])\n",
        "    data['e1_distance'] = data['e1_distance'].map(lambda x:x[:50])\n",
        "    data['e2_distance'] = data['e2_distance'].map(lambda x:x[:50])\n",
        "    data['word_idx'] = data['word_idx'].map(lambda x:np.array(x))\n",
        "    data['e1_distance'] = data['e1_distance'].map(lambda x:np.array(x))\n",
        "    data['e2_distance'] = data['e2_distance'].map(lambda x:np.array(x))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6SJfMO7sbHfj",
        "outputId": "8eaab2c2-1c6b-4f41-8de3-50efd32f3e42"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# 对于相同实体对的句子，进行集包处理\\ntrain_idx_grp = get_group_data(sent_train)\\ndev_idx_grp = get_group_data(sent_dev)\\ntest_idx_grp = get_group_data(sent_test)\\n# 对于包中长度没有达到要求的，补上句子\\ntrain_idx_grp = get_group_padding(train_idx_grp)\\ndev_idx_grp = get_group_padding(dev_idx_grp)\\ntest_idx_grp = get_group_padding(test_idx_grp)'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 对于长度不足50的句子用0补充到50\n",
        "sent_train = get_sent_padding(sent_train)\n",
        "sent_dev = get_sent_padding(sent_dev)\n",
        "sent_test = get_sent_padding(sent_test)\n",
        "\n",
        "'''\n",
        "# 对于相同实体对的句子，进行集包处理\n",
        "train_idx_grp = get_group_data(sent_train)\n",
        "dev_idx_grp = get_group_data(sent_dev)\n",
        "test_idx_grp = get_group_data(sent_test)\n",
        "# 对于包中长度没有达到要求的，补上句子\n",
        "train_idx_grp = get_group_padding(train_idx_grp)\n",
        "dev_idx_grp = get_group_padding(dev_idx_grp)\n",
        "test_idx_grp = get_group_padding(test_idx_grp)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3pmiRyyAenyz",
        "outputId": "dd6f0f95-6c26-41ac-be9a-dd2f15e6bb34"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# 为集包之后的训练集补上标签\\ntrain_label_grp = sent_train.groupby(['e1', 'e2']).apply(lambda x: list(set(x['label'].values))[0]).reset_index()\\ntrain_label_grp.columns = ['e1', 'e2', 'label']\\ntrain_idx_grp = train_idx_grp.merge(train_label_grp, on=['e1', 'e2'], how='left')\\n# 为集包之后的验证集补上标签\\ndev_label_grp = sent_dev.groupby(['e1', 'e2']).apply(lambda x: list(set(x['label'].values))[0]).reset_index()\\ndev_label_grp.columns = ['e1', 'e2', 'label']\\ndev_idx_grp = dev_idx_grp.merge(dev_label_grp, on=['e1', 'e2'], how='left')\""
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# 为集包之后的训练集补上标签\n",
        "train_label_grp = sent_train.groupby(['e1', 'e2']).apply(lambda x: list(set(x['label'].values))[0]).reset_index()\n",
        "train_label_grp.columns = ['e1', 'e2', 'label']\n",
        "train_idx_grp = train_idx_grp.merge(train_label_grp, on=['e1', 'e2'], how='left')\n",
        "# 为集包之后的验证集补上标签\n",
        "dev_label_grp = sent_dev.groupby(['e1', 'e2']).apply(lambda x: list(set(x['label'].values))[0]).reset_index()\n",
        "dev_label_grp.columns = ['e1', 'e2', 'label']\n",
        "dev_idx_grp = dev_idx_grp.merge(dev_label_grp, on=['e1', 'e2'], how='left')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2jyHwe4nfH5y",
        "outputId": "2b6b5950-8872-4d0e-8a45-f55f5faf3050"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'train_idx_grp_part=train_idx_grp.iloc[3300:]'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#0 的标签过多\n",
        "'''train_idx_grp_part=train_idx_grp.iloc[3300:]'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "u-_0slCsQeky",
        "outputId": "70799e59-fdba-474d-8efb-48e364241005"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-503ff012-f1b2-40ad-a568-376bc765346b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_id</th>\n",
              "      <th>e1</th>\n",
              "      <th>e2</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_seg</th>\n",
              "      <th>e1_idx</th>\n",
              "      <th>e2_idx</th>\n",
              "      <th>e1_distance</th>\n",
              "      <th>e2_distance</th>\n",
              "      <th>word_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_SENT_ID_000001</td>\n",
              "      <td>金泰熙</td>\n",
              "      <td>金东</td>\n",
              "      <td>韩国 梦想 演唱会 第十届 2004 年 : mc : 金泰熙 ， 金东 万</td>\n",
              "      <td>0</td>\n",
              "      <td>[韩国, 梦想, 演唱会, 第十届, 2004, 年, :, mc, :, 金泰熙, ，, ...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 3, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, ...</td>\n",
              "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 8, 1, 11, 1, 12, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_SENT_ID_000002</td>\n",
              "      <td>辛文山</td>\n",
              "      <td>林散之</td>\n",
              "      <td>林散之 先生 等 当代 名家 对 辛文山 先生 的 书法 均 有 精辟 的 点评 ， 对 书...</td>\n",
              "      <td>0</td>\n",
              "      <td>[林散之, 先生, 等, 当代, 名家, 对, 辛文山, 先生, 的, 书法, 均, 有, ...</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, ...</td>\n",
              "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
              "      <td>[1, 14, 15, 16, 17, 18, 1, 14, 19, 20, 21, 22,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-503ff012-f1b2-40ad-a568-376bc765346b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-503ff012-f1b2-40ad-a568-376bc765346b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-503ff012-f1b2-40ad-a568-376bc765346b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                sent_id   e1   e2  \\\n",
              "0  TRAIN_SENT_ID_000001  金泰熙   金东   \n",
              "1  TRAIN_SENT_ID_000002  辛文山  林散之   \n",
              "\n",
              "                                                text  label  \\\n",
              "0             韩国 梦想 演唱会 第十届 2004 年 : mc : 金泰熙 ， 金东 万      0   \n",
              "1  林散之 先生 等 当代 名家 对 辛文山 先生 的 书法 均 有 精辟 的 点评 ， 对 书...      0   \n",
              "\n",
              "                                            text_seg  e1_idx  e2_idx  \\\n",
              "0  [韩国, 梦想, 演唱会, 第十届, 2004, 年, :, mc, :, 金泰熙, ，, ...       9      11   \n",
              "1  [林散之, 先生, 等, 当代, 名家, 对, 辛文山, 先生, 的, 书法, 均, 有, ...       6       0   \n",
              "\n",
              "                                         e1_distance  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 3, 0, 0, ...   \n",
              "1  [1, 1, 1, 1, 1, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, ...   \n",
              "\n",
              "                                         e2_distance  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, ...   \n",
              "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
              "\n",
              "                                          word_index  \n",
              "0  [2, 3, 4, 5, 6, 7, 8, 9, 8, 1, 11, 1, 12, 0, 0...  \n",
              "1  [1, 14, 15, 16, 17, 18, 1, 14, 19, 20, 21, 22,...  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lAMRC7YGfHDo"
      },
      "outputs": [],
      "source": [
        "part_train = np.array([v for v in sent_train['word_index'].values])\n",
        "part_train_pos1 = np.array([v for v in sent_train['e1_distance'].values])\n",
        "part_train_pos2 = np.array([v for v in sent_train['e2_distance'].values])\n",
        "part_label = sent_train['label'].values\n",
        "\n",
        "part_dev = np.array([v for v in sent_dev['word_index'].values])\n",
        "part_dev_pos1 = np.array([v for v in sent_dev['e1_distance'].values])\n",
        "part_dev_pos2 = np.array([v for v in sent_dev['e2_distance'].values])\n",
        "part_dev_label = sent_dev['label'].values\n",
        "\n",
        "part_test = np.array([v for v in sent_test['word_index'].values])\n",
        "part_test_pos1 = np.array([v for v in sent_test['e1_distance'].values])\n",
        "part_test_pos2 = np.array([v for v in sent_test['e2_distance'].values])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc5xYyAfPRSv",
        "outputId": "7161f101-56b9-48b5-dccd-00d461212fb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(281241, 50)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "part_train_pos1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlwmyAQqfjAF"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yqJ_iZriXRWC"
      },
      "outputs": [],
      "source": [
        "# LSTM的输入是实体1的位置信息+实体2的微信信息+嵌入信息。LSTM的output保存了最后一层的输出h。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_FgJzk4vfiYs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)  \n",
        "\n",
        "class BiLSTM_ATT(nn.Module):\n",
        "    def __init__(self,config,embedding_pre):\n",
        "        super(BiLSTM_ATT,self).__init__()\n",
        "        self.batch = config['BATCH']\n",
        "        \n",
        "        self.embedding_size = config['EMBEDDING_SIZE']\n",
        "        self.embedding_dim = config['EMBEDDING_DIM']\n",
        "        \n",
        "        self.hidden_dim = config['HIDDEN_DIM']\n",
        "        self.tag_size = config['TAG_SIZE']\n",
        "        \n",
        "        self.pos_size = config['POS_SIZE']\n",
        "        self.pos_dim = config['POS_DIM']\n",
        "        \n",
        "        self.pretrained = config['pretrained']\n",
        "        if self.pretrained:\n",
        "            #self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_pre))\n",
        "            self.word_embeds = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_pre),freeze=False)\n",
        "        else:\n",
        "            self.word_embeds = nn.Embedding(self.embedding_size,self.embedding_dim)\n",
        "        \n",
        "        self.pos1_embeds = nn.Embedding(self.pos_size,self.pos_dim)\n",
        "        self.pos2_embeds = nn.Embedding(self.pos_size,self.pos_dim)\n",
        "        self.relation_embeds = nn.Embedding(self.tag_size,self.hidden_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim+self.pos_dim*2,hidden_size=self.hidden_dim//2,num_layers=1, bidirectional=True)\n",
        "        self.hidden2tag = nn.Linear(self.hidden_dim,self.tag_size)\n",
        "        \n",
        "        self.dropout_emb=nn.Dropout(p=0.5)\n",
        "        self.dropout_lstm=nn.Dropout(p=0.5)\n",
        "        self.dropout_att=nn.Dropout(p=0.5)\n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "        self.att_weight = nn.Parameter(torch.randn(self.batch,1,self.hidden_dim))\n",
        "        self.relation_bias = nn.Parameter(torch.randn(self.batch,self.tag_size,1))\n",
        "        \n",
        "    def init_hidden(self):\n",
        "        return torch.randn(2, self.batch, self.hidden_dim // 2)\n",
        "        \n",
        "    def init_hidden_lstm(self):\n",
        "        return (torch.randn(2, self.batch, self.hidden_dim // 2),\n",
        "                torch.randn(2, self.batch, self.hidden_dim // 2))\n",
        "                \n",
        "    def attention(self,H):\n",
        "        M = F.tanh(H)\n",
        "        a = F.softmax(torch.bmm(self.att_weight,M),2)\n",
        "        a = torch.transpose(a,1,2)\n",
        "        return torch.bmm(H,a)\n",
        "        \n",
        "    \n",
        "                \n",
        "    def forward(self,sentence,pos1,pos2):\n",
        "\n",
        "        self.hidden = self.init_hidden_lstm()\n",
        "\n",
        "        embeds = torch.cat((self.word_embeds(sentence),self.pos1_embeds(pos1),self.pos2_embeds(pos2)),2)\n",
        "        \n",
        "        embeds = torch.transpose(embeds,0,1)\n",
        "\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        \n",
        "        lstm_out = torch.transpose(lstm_out,0,1)\n",
        "        lstm_out = torch.transpose(lstm_out,1,2)\n",
        "        \n",
        "        lstm_out = self.dropout_lstm(lstm_out)\n",
        "        att_out = F.tanh(self.attention(lstm_out))\n",
        "        #att_out = self.dropout_att(att_out)\n",
        "        \n",
        "        relation = torch.tensor([i for i in range(self.tag_size)],dtype = torch.long).repeat(self.batch, 1)\n",
        "\n",
        "        relation = self.relation_embeds(relation)\n",
        "        \n",
        "        res = torch.add(torch.bmm(relation,att_out),self.relation_bias)\n",
        "        \n",
        "        res = F.softmax(res,1)\n",
        "\n",
        "        \n",
        "        return res.view(self.batch,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1M0qC-xZrkg",
        "outputId": "b9a2bc91-8be5-4ec8-c03e-4305806ba0f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "88851"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_matrix.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiVSPyE7Bg3z",
        "outputId": "5d511794-600c-4482-85b9-95903a36bbe7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import codecs\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as D\n",
        "from torch.autograd import Variable        \n",
        "\n",
        "EMBEDDING_SIZE = word_matrix.shape[0]\n",
        "EMBEDDING_DIM = 128\n",
        "\n",
        "POS_SIZE = 100  #不同数据集这里可能会报错。\n",
        "POS_DIM = 128\n",
        "\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "TAG_SIZE = 35\n",
        "\n",
        "BATCH = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "config={}\n",
        "config['EMBEDDING_SIZE'] = EMBEDDING_SIZE\n",
        "config['EMBEDDING_DIM'] = EMBEDDING_DIM\n",
        "config['POS_SIZE'] = POS_SIZE\n",
        "config['POS_DIM'] = POS_DIM\n",
        "config['HIDDEN_DIM'] = HIDDEN_DIM\n",
        "config['TAG_SIZE'] = TAG_SIZE\n",
        "config['BATCH'] = BATCH\n",
        "config[\"pretrained\"]=True\n",
        "\n",
        "learning_rate = 0.0005\n",
        "\n",
        "\n",
        "embedding_pre = word_matrix\n",
        "\n",
        "model = BiLSTM_ATT(config,embedding_pre)\n",
        "#model = torch.load('model/model_epoch20.pkl')\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss(size_average=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1dkVnej0bWjj"
      },
      "outputs": [],
      "source": [
        "train = torch.LongTensor(part_train[:len(part_train)-len(part_train)%BATCH])\n",
        "\n",
        "position1 = torch.LongTensor(part_train_pos1[:len(train)-len(train)%BATCH])\n",
        "position2 = torch.LongTensor(part_train_pos2[:len(train)-len(train)%BATCH])\n",
        "labels = torch.LongTensor(part_label[:len(train)-len(train)%BATCH])\n",
        "train_datasets = D.TensorDataset(train,position1,position2,labels)\n",
        "train_dataloader = D.DataLoader(train_datasets,BATCH,True,num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6XIMJQ7HGng3"
      },
      "outputs": [],
      "source": [
        "test = torch.LongTensor(part_dev[:len(part_dev)-len(part_dev)%BATCH])\n",
        "position1_t = torch.LongTensor(part_dev_pos1[:len(test)-len(test)%BATCH])\n",
        "position2_t = torch.LongTensor(part_dev_pos2[:len(test)-len(test)%BATCH])\n",
        "labels_t = torch.LongTensor(part_dev_label[:len(test)-len(test)%BATCH])\n",
        "test_datasets = D.TensorDataset(test,position1_t,position2_t,labels_t)\n",
        "test_dataloader = D.DataLoader(test_datasets,BATCH,True,num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzfraHgFGWPj",
        "outputId": "9a429387-d166-4e76-b93a-f5ab0da24c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: 86.95273384160218 %\n",
            "epoch: 1\n",
            "train: 87.20449761037779 %\n",
            "epoch: 2\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(\"epoch:\",epoch)\n",
        "    acc=0\n",
        "    total=0\n",
        "    \n",
        "    for sentence,pos1,pos2,tag in train_dataloader:\n",
        "        print(tag)\n",
        "        sentence = Variable(sentence)\n",
        "        pos1 = Variable(pos1)\n",
        "        pos2 = Variable(pos2)\n",
        "        y = model(sentence,pos1,pos2)  \n",
        "        tags = Variable(tag)\n",
        "        loss = criterion(y, tags)      \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()    \n",
        "       \n",
        "        y = np.argmax(y.data.numpy(),axis=1)\n",
        "\n",
        "        for y1,y2 in zip(y,tag):\n",
        "            if y1==y2:\n",
        "                acc+=1\n",
        "            total+=1\n",
        "        \n",
        "    print (\"train:\",100*float(acc)/total,\"%\")\n",
        "      \n",
        "    acc_t=0\n",
        "    total_t=0\n",
        "    count_predict = [0]*34\n",
        "    count_total = [0]*34\n",
        "    count_right = [0]*34\n",
        "    for sentence,pos1,pos2,tag in test_dataloader:\n",
        "        sentence = Variable(sentence)\n",
        "        pos1 = Variable(pos1)\n",
        "        pos2 = Variable(pos2)\n",
        "        y = model(sentence,pos1,pos2)\n",
        "        y = np.argmax(y.data.numpy(),axis=1)\n",
        "        for y1,y2 in zip(y,tag):\n",
        "            count_predict[y1]+=1\n",
        "            count_total[y2]+=1\n",
        "            if y1==y2:\n",
        "                count_right[y1]+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC9uzl9YJBpp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "关系抽取_processing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}